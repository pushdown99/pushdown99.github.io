---
layout: post
title: 'vSphere' 
author: haeyeon.hwang
tags: [cloud]
description: >
  vSphere 관련 내용 
image: /assets/img/blog/vSphere.png
hide_image: true
---

{:.no_toc}
1. this unordered seed list will be replaced by toc as unordered list
{:toc}

## **vSphere 개요**

---

#### **vSphere**
- 클라우드 및 SDDC환경에서 컴퓨팅 리소스(가상머신)를 제공하고 관리하는 역할
- 가상머신을 생성하고 실행하는 **ESXi** Hypervisor와 다수의 ESXi를 중앙관리 할 수 있는 **vCenter**가 포함된 패키지
- 클라우드 서비스를 위한 가상화 인프라 구성요소 중 운영체제, 어플리케이션이 실행되는 Computing 영역을 담당
- 하나의 물리적인 서버에 다수의 가상머신(VM)의 생성/삭제 등 관리
- VM이 실행될 수 있도록 CPU/메모리/디스크등의 자원을 관리
- 주요기능

    주요기능|상세내용
    ---|---
    가상화 구성|가상화는 하나의 물리적 서버에 여러 개의 가상 서버를 생성하는 기술</br>가상머신의 데이터는 스토리지에 이미지 파일로 저장됨
    VM 마이그레이션 (vMotion)|VM의 중단 없이 온라인 마이그레이션 기능 지원</br>종료된 VM을 실행 할 때 원하는 Host를 지정하여 부팅 가능
    리소스 분배 (DRS; Distributed Resource Scheduler)|vCenter는 각 ESXi들의 리소스 사용량을 실시간 모니터링</br>DRS기능은 리소스 사용량이 높은 서버에 있는 VM을 여유로운 서버로 이동
    장애 시 빠른 복구 (HA)|vCenter는 장애가 발생한 ESXi에서 동작하던 VM을 다른 호스트에서 재기동함</br>VM별로 HA될 호스트를 미리 선정하여 각 ESXi에 통지 하므로 vCenter 장애시에도 HA는 정상 동작

#### **ESXi**
- VMware에서 제작한 하이퍼바이저, VM을 생성/삭제/실행하는 역할로  vCenter 없이 단독으로 운영 가능
- 하드웨어를 효과적으로 파티셔닝하여 운영체제, 어플리케이션에 구애 받지 않고 효율적으로 활용 할 수 있도록 함
- ESXi 자원 분배

    구분|내용
    ---|---
    CPU|물리서버의 CPU를 vCPU단위로 할당</br>CPU가 10Core라면 VM별 최대 10vCpu할당 가능</br>자원 경합 발생시 Clock을 분할하여 사용
    메모리|물리 서버의 메모리를 분할하여 VM에 할당</br>오버 커밋 가능
    스토리지|VM은 의 DISK는 파일 형태로 스토리지에 저장</br>Thin/Thick 프로비저닝 지원</br>스토리지 용량 범위내에서 다수의 DISK를 생성하고 개별적으로 용량 할당 가능</br><u>오버 프로비저닝</u> 가능</br>
    네트워크|가상스위치를 통해 물리 네트워크에 연결</br>가상스위치는 Access/Trunk 모드 지원</br>VM 별 VLAN 할당 가능

- 리소스관리 / CPU
  - vCPU의 Core 분배
    - 물리서버의 CPU Core를 vCPU 단위로 할당
    - CPU가 8Core라면 VM별 최대 8vCPU 할당 가능
    - 물리 CPU 1개 Core당 다수의 vCPU 할당 가능
    - 컨설팅시 VM의 CPU사용량에 따라 적절한 vCPU:pCPU비율 산정 
  
        용도 별|vCPU:pCPU 비율
        ---|---
        일반|1:3
        사용량이 적은 서버|1:5
        고성능 실시간 처리|1:1
        vSphere6 기준|최대 1:32
    
  - vCPU의 Clock 분배
    - 자원 경합 발생시 vCPU 수에 비례하여 Clock 할당
    - 최대 사용가능 Clock = 물리 Core Clock * vCPU할당 개수 (예: 8 vCPU VM, 3GHz 물리 CPU의 경우 8 * 3Ghz= 24Ghz)

- 리소스관리 / 메모리

  - 메모리 용량 분배
    - 서버의 메모리를 각 VM에 할당 가능
    - ESXi는 할당량 / 사용량을 분리하여 관리

        구분|내용|비고
        ---|---|---
        할당량|VM에서 사용 할 수 있는 최대용량<td rowspan="2">대부분의 경우 사용량이 할당량 보다 적으므로 Overcommit가능</td>
        사용량|VM에서 실제 사용중인 용량|

  - 메모리 Overcommit
    - Overcommit: 실제 메모리 양보다 더 많은 용량을 VM에 할당
    - VM의 메모리 사용량의 총합이 실제 메모리의 용량 미만이라면 자원을 최대 효율로 사용 할 수 있음
    - Overcommit 상태에서 VM의 메모리 사용량이 실제 메모리 용량을 초과하는경우 DISK의 일부를 메모리처럼 사용 (SWAP, 성능이 매우 저하됨)
    
- 리소스관리 / 스토리지

  - 스토리지 프로비저닝 방법

    스토리지 프로비저닝|내용|비고
    ---|---|---
    Thin|한계치를 정해놓고 실제 사용량만큼 공간을 할당|Reclaiming: Thin 프로비저닝 사용시 VM에서 데이터가 삭제된 경우 삭제된 만큼 공간을 다시 회수하는 작업
    Thick|사용용량과 상관없이 전체용량을 할당|
    
  - VMDK (VM 디스크 이미지 파일)
    - VM의 디스크는 VMDK 확장자 파일로 저장됨
    - VM 별로 여러 개의 디스크를 생성 할 수 있으며, 각각 다른 VMDK 파일에 저장됨
    - VMDK 파일 별로 프로비저닝 형태 지정 가능 (Thin | Thick)
    
- 리소스관리 / 네트워크

  - 가상 스위치
    - **물리스위치 <-> VM간 L2네트워크 연결**
    - 서버에 장착된 랜카드를 <u>업링크</u>로 사용
    - 물리스위치와 Access/Trunk로 연결
    - CDP(Cisco Discovery Protocol) / LLDP(Link Layer Discovery Protocol; </br>IEEE 802.1ab/Station and Media Access Control connectivity discovery)지원
    - <u>STP를 지원하지 않음(L2 Flooding 없음)</u>
      - 외부에서 들어온 Broadcast/Multicast는 내부 VM에게만 전달
      - 외부에서 들어온 Unknown Unicast는 드랍
      - 내부에서 발생된 BUM은 외부로 전달
      - 외부로 전달된 패킷이 헤어핀되어 돌아오면 드랍

  - 포트 그룹
    - 가상스위치에 존재하는 가상 포트들의 그룹
    - 포트그룹에 VLAN 할당 및 VM 연결
    - VM은 복수의 vNIC 보유 가능, vNIC 별 포트그룹 지정 가능
    - 포트 그룹 별 업링크 지정 및 Fail-over 방식 및 순서 구성 가능
    - 업링크는 1 ~ 32개 구성 가능
    - 업링크 트래픽 로드밸런싱 지원

  - VMware에서 사용하는 인터페이스 명칭 및 설명

    인터페이스명|별칭|용도|넘버링|비고
    ---|---|---|---|---
    Vmkernel|vmk|ESXi에서 내부적으로 쓰는 인터페이스</br> * 사용자가 ESXi에 Web으로 접속할때</br> * vMotion등 ESXi간 트래픽 전달</br> * NFS/ISCSI등 NAS 스토리지 연결</br>포트그룹에 연결하여 사용</br>인터페이스별 MTU설정 가능(ex. 관리 1500 / 스토리지 9000)</br>VMware 내부 서비스용으로 이용 시 아래처럼 용도지정 필수 (외부 스토리지등 연동시 지정 불필요)|Vmk0 ~ N|Vmk마다 단수/복수 역할 지정 가능</br>- Vmk1 = 관리</br>- Vmk2 = vMotion/복제</br>- Vmk3 = 스토리지
    vmnic|pnic|서버에 장착된 랜카드 포트와 1:1 매핑</br>서버 하드웨어 구성 및 ESXi설치 후 반드시 파악 필요</br>예시:</br>- vmnic0 = Slot1에 장착된 NIC에 1번 포트</br>- vmnic1 = Slot1에 장착된 NIC에 2번 포트</br>- vmnic3 = Slot2에 장착된 NIC에 1번 포트|Vmnic0 ~ N|서버 물리 포트 10개</br>= vmnic 10개
    vnic|가상머신 랜카드|가상머신에 할당하는 가상 랜카드</br>실제 서버의 NIC의 1개의 포트와 같음</br>포트그룹에 연결하여 사용(1vNIC : 1Portgroup)|Network Adapter1 ~ N|
    Uplink|가상스위치 업링크|vSwitch에서 사용하는 Uplink</br>Vmnic과 1:1로 매핑하여 사용</br>예시:</br>- vSwitch-MGMT의 Uplink1 = vmnic0</br>- vSwitch-MGMT의 Uplink2 = vmnic2|Uplink1 ~ N|

    vSphere 가상스위치 방식|내용|트래픽 로드밸런싱 지원
    ---|---|---
    표준스위치</br>(vSS; vSphere Standard Switch)|라이선스 상관 없이모든 ESXi 호스트에서 사용 가능</br>호스트별 vSwitch 및 포트그룹 생성</br>본딩 지원(LACP 제외) A-A, A-S</br>포트 미러링 미지원</br>CDP만 지원|4가지
    분산스위치</br>(vDS; vNetwork Distributed Switch)|vSphere Enterprise Plus 라이선스 필요</br>vCenter 필요</br>설정 변경시 분산스위치를 사용하는 모든 호스트에 일괄 적용됨</br>본딩 지원(LACP 포함) A-A, A-S</br>포트 미러링 지원(RSPAN 지원 스위치 필요)</br>CDP/LLDP 지원</br>트래픽 쉐이핑 (트래픽 종류 별 QoS) 지원|5가지

    - LAG(Link Aggregation Group)
      - Link Aggreation: 여러 개의 물리 포트를 묶어서 하나의 논리적인 포트처럼 사용하는 기술
      - LAG: Link Aggregation 을 구성할 때, 물리적인 포트를 하나로 묶는 그룹
      - 대역폭 증가 및 물리적인 Link의 이중화를 통해 Link의 효율성을 증가시킴

      LAG 구분|상세 내용
      ---|---
      Static LAG|장비간 제어 메시지(Control Inforamtion)를 주고 받지 않고 단순히 포트만 묶음</br>스위치 피어간 LAG 관련 신호를 주고받지 않음. 각각의 피어에서 독립적으로 LAG를 구성하기만 하면 됨. 정상적으로 구성이 완료될 시 LAG가 작동함.</br>-> 권장되지 않음(한쪽에서 잘못 구성하더라도 피어에서 감지되지 않기 때문)</br>관리자가 서로 연결되는 장치, 각 포트에 일일이 설정을 통해 LAG를 묶는 방법
      Dynamic LAG=LACP|장비가 LACP를 지원하고 포트에 LACP를 활성화시켜 두면 LACP가 활성화된 포트끼리 상호 연결 되었을 때, 각 장치가 자동으로 협상을 통해 LAG를 묶는 방법</br>LACP라는 프로토콜을 사용하여 제어 메시지(Control Information)를 주고 받으며 동작</br>802.3ad 표준</br>링크의 장애를 감지하고 LAG 맴버 포트가 동일한 장치에서 구성되도록 함

    - LACP(Link Aggregation Control Protocol)

    구분|상세 내용
    ---|---
    목적|(1) High Performance (= Bandwidth 향상)</br>- 개별링크의 용량 한계 극복 가능</br>- 추가 비용 없이 대역폭을 증가시켜 성능을 올릴 수 있음</br>(2) High Availability</br>- 네트워크 디바이스나 회선문제로 인해 발생 가능한 최소한의 네트워크 가용성을 보장</br>- 다수의 물리적 네트워크에서 일부 interface가 고장이 발생하여 연결이 끊어지는 경우 나머지 네트워크 interface만으로 논리적 네트워크 interface를 구성하여 사용할 수 있도록 함</br>(3) LB(Load Balance) : 워크 로드 분산</br>- Group에 속하는 각각의 실제 포트에 traffic이 전달되는 방법</br>(4) Loop(Storm)방지 : 패킷 루핑 방지
    설정|interface port-channel channel-number[1~4096]

  - 회선 이중화시 트래픽 로드밸런싱 유형

    트래픽 로드밸런싱|내용
    ---|---
    하나의 VM은 한 개의 Uplink만 이용|
    다수의 VM에서 트래픽 발생시,</br>아래 규칙에 따라 부하분산|VM이 연결된 vSwith의 가상 포트 기반 라우팅</br>소스 MAC 해시 기반 라우팅</br>IP 해시 기반</br>물리적 NIC 로드 기반 라우팅</br>명시적 장애 조치 순서 사용

  - 태깅 방식에 따른 구분

    가상 스위치 태깅|외부 스위치 태깅|가상 게스트 태깅
    ---|---|---
    물리스위치에서 Trunk 구성</br>가상스위치에서 포트 그룹 생성시 VLAN Tag|물리스위치에서 Access 구성</br>가상스위치에서 포트그룹 생성시 VLAN 미지정</br>포트 그룹 생성시 VLAN을 Tag하면 통신 불가|물리스위치에서 Trunk 구성</br>가상스위치에서 Trunk Mode로 포트그룹 생성</br>게스트 OS(VM)에서 VM 태그
    
#### **vCenter**
- 다수의 ESXi 및 VM을 중앙에서 관리하기 위한 어플라이언스
- HA / DRS등 ESXi 간 연계가 필요한 기능들의 제어 역할을 담당
- vCenter 서비스
  - ESXi 및 VM의 제어 및 관리
  - 통합관리를 위한 UI 제공
  - 로그 및 덤프 수집
  - 구성 / 관리 DB (ex-VM, vSwitch, Datastore, Cluster 등)

- Platform Service Controller
 
    기능구분|내용
    ---|---
    AAA|사용자생성, 사용자별 권한 할당, 인증
    SSO|자체 사용자 DB 및 외부 AD/LDAP 연동</br>여러 vCenter 연동 시 (linked mode), 계정정보 동기화
    라이선스 / 인증서 관리|

- **vCenter 구성 요소**
 
    구성요소|내용|비고
    ---|---|---
    vCenter|관리의 최상위 단위</br>vCenter 장애 시 중앙관리가 불가능 하므로 AZ(Availability Zone)설계 시 적절한 수량으로 분리|
    Datacenter|vCenter 내부의 논리적인 관리 단위</br>ESXi 그룹핑/권한 할당을 위한 컨테이너 단위(별도 기능 X)|
    Cluster|ESXi 호스트들의 집합</br>ESXi/VM 관리 정책을 적용하는 단위</br>HA/DRS가 동작하는 범위</br>리소스 풀 구성 시 가용한 리소스(CPU/MEM)최대 범위|vDS/Datastore/vMotion은 여러 Cluster에 걸쳐서 적용/실행 가능함
    Enhanced Linked Mode (ELM)|여러 vCenter 연동하는 기능</br>하나의 vCenter에 로그인하면 연동된 모든 vCenter및 하위 개체 제어 가능

- vCenter HA
  - 장애를 대비하기 위한 vCenter 이중화 구성, Hearbeat 교환을 위한 별도 네트워크 필요
  - 평시: 구성/DB 실시간 동기화(A->S)
  - 장애시: Standby가 활성화됨(VIP 활성화)
  - 라이선스 추가구매 없이  HA구성 가능
  - Witness: A/S 두개의 vCenter가 모두 살아있고 두 사이트간 네트워크 단절이 발생 시, 어느 vCenter가 Active가 될 것인지 판정하는 역할 (스플릿 브레인; Split Brain 방지 - 쿼럼; Quorum/정족수) 
  

